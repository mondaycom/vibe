name: Performance Testing

on:
  pull_request:
    paths:
      - "packages/core/src/components/**"
      - "packages/components/**"

permissions:
  pull-requests: write

jobs:
  build:
    name: Build
    uses: ./.github/workflows/build-and-upload.yml
    with:
      skip_release_artifacts: true
    secrets:
      npm_token: ${{ secrets.npm_token }}

  test-pr:
    name: Test PR Branch
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 20

    steps:
      - uses: actions/checkout@v4

      - name: Run Setup
        uses: ./.github/actions/setup
        with:
          npm_token: ${{ secrets.npm_token }}

      - name: Download build artifacts
        uses: ./.github/actions/download-builds
        if: ${{ needs.build.outputs.has_changes == 'true' }}

      - name: Install Playwright
        run: ./node_modules/playwright/cli.js install --with-deps chromium

      - name: Run performance tests
        run: |
          mkdir -p scripts/performance/reports
          cd packages/docs
          yarn storybook &
          STORYBOOK_PID=$!
          trap 'kill $STORYBOOK_PID 2>/dev/null || true' EXIT
          npx wait-on http://localhost:7008 --timeout 120000 || exit 1
          PERFORMANCE_TEST=true ./node_modules/.bin/test-storybook --url http://localhost:7008 --maxWorkers=4 || true
        continue-on-error: true

      - name: Aggregate metrics
        run: |
          node scripts/performance/aggregate-metrics.js
          cp scripts/performance/reports/metrics.json scripts/performance/reports/pr.json 2>/dev/null || \
            echo '{"timestamp":"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'","components":{}}' > scripts/performance/reports/pr.json

      - name: Upload PR metrics
        uses: actions/upload-artifact@v4
        with:
          name: pr-metrics
          path: scripts/performance/reports/pr.json
          retention-days: 1

  test-base:
    name: Test Base Branch
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 20

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Checkout base commit
        run: |
          BASE=$(git merge-base origin/${{ github.event.pull_request.base.ref }} ${{ github.event.pull_request.head.sha }})
          echo "Testing base commit: $BASE"
          git checkout $BASE

      - name: Run Setup
        uses: ./.github/actions/setup
        with:
          npm_token: ${{ secrets.npm_token }}

      - name: Build
        run: yarn build

      - name: Install Playwright
        run: ./node_modules/playwright/cli.js install --with-deps chromium

      - name: Run performance tests
        run: |
          mkdir -p scripts/performance/reports
          cd packages/docs
          yarn storybook &
          STORYBOOK_PID=$!
          trap 'kill $STORYBOOK_PID 2>/dev/null || true' EXIT
          npx wait-on http://localhost:7008 --timeout 120000 || exit 1
          PERFORMANCE_TEST=true ./node_modules/.bin/test-storybook --url http://localhost:7008 --maxWorkers=4 || true
        continue-on-error: true

      - name: Aggregate metrics
        run: |
          node scripts/performance/aggregate-metrics.js
          cp scripts/performance/reports/metrics.json scripts/performance/reports/base.json 2>/dev/null || \
            echo '{"timestamp":"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'","components":{}}' > scripts/performance/reports/base.json

      - name: Upload base metrics
        uses: actions/upload-artifact@v4
        with:
          name: base-metrics
          path: scripts/performance/reports/base.json
          retention-days: 1

  compare:
    name: Compare & Report
    runs-on: ubuntu-latest
    needs: [test-pr, test-base]
    if: always() && needs.test-pr.result != 'cancelled' && needs.test-base.result != 'cancelled'

    steps:
      - uses: actions/checkout@v4

      - name: Download PR metrics
        uses: actions/download-artifact@v4
        with:
          name: pr-metrics
          path: scripts/performance/reports
        continue-on-error: true

      - name: Download base metrics
        uses: actions/download-artifact@v4
        with:
          name: base-metrics
          path: scripts/performance/reports
        continue-on-error: true

      - name: Ensure metrics files exist
        run: |
          mkdir -p scripts/performance/reports
          [ -f scripts/performance/reports/pr.json ] || echo '{"timestamp":"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'","components":{}}' > scripts/performance/reports/pr.json
          [ -f scripts/performance/reports/base.json ] || echo '{"timestamp":"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'","components":{}}' > scripts/performance/reports/base.json

      - name: Generate report
        run: node scripts/performance/compare-metrics.js
        continue-on-error: true

      - name: Post PR comment
        uses: marocchino/sticky-pull-request-comment@v2
        if: hashFiles('scripts/performance/reports/comparison.md') != ''
        with:
          header: performance
          path: scripts/performance/reports/comparison.md

      - name: Upload all reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-reports
          path: scripts/performance/reports/*
          retention-days: 7
